{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Step 1: Get current directory \n",
    "current_directory = os.getcwd()        # '/home/bear-b/users/jshi008/IvyProjects/FIDLA/train_WaLeF_models'\n",
    "\n",
    "# Step 2: Get path of parent directory (one level up)\n",
    "parent_directory = os.path.dirname(current_directory)    # '/home/bear-b/users/jshi008/IvyProjects/FIDLA'\n",
    "\n",
    "# Step 3: Append parent directory to sys.path\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data_utils\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "from baselines.cnn import CNN\n",
    "from preprocess.BaselinePrerocess import baseline_process\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77069, 96, 16]) torch.Size([9634, 96, 16]) torch.Size([19268, 96, 16]) torch.Size([77069, 96]) torch.Size([9634, 96]) torch.Size([19268, 96])\n"
     ]
    }
   ],
   "source": [
    "# ====== preprocessing parameters ======\n",
    "n_hours = 72\n",
    "K = 24 \n",
    "masked_value = 1e-10\n",
    "split_1 = 0.8\n",
    "split_2 = 0.9\n",
    "\n",
    "train_X_mask, val_X_mask, test_X_mask, \\\n",
    "train_ws_y, val_ws_y, test_ws_y, \\\n",
    "scaler, ws_scaler = baseline_process(n_hours, K, masked_value, split_1, split_2)\n",
    "\n",
    "train_X_mask, val_X_mask, test_X_mask, train_ws_y, val_ws_y, test_ws_y = torch.from_numpy(train_X_mask), torch.from_numpy(val_X_mask), torch.from_numpy(test_X_mask), torch.from_numpy(train_ws_y), torch.from_numpy(val_ws_y), torch.from_numpy(test_ws_y)\n",
    "\n",
    "# train_X_mask = train_X_mask.permute(0, 2, 1)\n",
    "# val_X_mask = val_X_mask.permute(0, 2, 1)\n",
    "# test_X_mask = test_X_mask.permute(0, 2, 1)\n",
    "print(train_X_mask.shape, val_X_mask.shape, test_X_mask.shape, train_ws_y.shape, val_ws_y.shape, test_ws_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_loader = data_utils.DataLoader(data_utils.TensorDataset(train_X_mask, train_ws_y), batch_size=batch_size, shuffle=True)\n",
    "val_loader = data_utils.DataLoader(data_utils.TensorDataset(val_X_mask, val_ws_y), batch_size=batch_size, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(data_utils.TensorDataset(test_X_mask, test_ws_y), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dont know how incorporate L1L2 regularization into  the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 64\n",
    "mlp_unit2 = 16\n",
    "dropout = 0.1\n",
    "l1_reg = 1e-5\n",
    "l2_reg = 1e-5\n",
    "learning_rate = 1e-3\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 500\n",
    "EPOCHS = 3000\n",
    "BATCH = 512\n",
    "input_shape = train_X_mask.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_mask.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape, mlp_unit1, mlp_unit2, l1_reg, l2_reg, dropout, masked_value):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.masked_value = masked_value\n",
    "        \n",
    "        self.dense1 = nn.Linear(input_shape[1], mlp_unit1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.dense2 = nn.Linear(mlp_unit1, mlp_unit2)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.output_layer = nn.Linear(input_shape[0] * mlp_unit2, 96)\n",
    "        \n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.masked_fill(x == self.masked_value, 0)\n",
    "        \n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.dense2(x))\n",
    "        x = self.dropout2(x)\n",
    "        # print(\"Dense 2: \", x.shape)\n",
    "        \n",
    "\n",
    "        x = self.flatten(x)\n",
    "        # print(\"flatten: \", x.shape)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "inp = torch.rand([1, 96, 16]).to(device)\n",
    "\n",
    "model = MLP(input_shape, mlp_unit1, mlp_unit2, l1_reg, l2_reg, dropout, masked_value).to(device)\n",
    "out = model(inp)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import UninitializedParameter\n",
    "\n",
    "def count_parameters(model):\n",
    "    dummy_input = torch.randn(1, 16, 96)\n",
    "    model.forward(dummy_input)\n",
    "    \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad and not isinstance(p, UninitializedParameter))\n",
    "\n",
    "total_params = count_parameters(cnn)\n",
    "print(total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
